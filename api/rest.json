{"swagger":"2.0","schemes":["http"],"host":"","basePath":"","info":{"contact":{"url":"https://vision.ai","name":"vision.ai API team"},"version":"0.2.0","title":"VMX v0.2 REST API for Object Detection and Recognition","description":"This document describes the VMX v0.2 REST API \n  which lets you programatically manage (create, delete, and edit) multiple VMXworker sessions. A VMXworker process is able to execute, create, and edit real-time object detection models made by VMX. Each worker will have its own endpoint URL: `/sessions/#sessionId`\n  \n  It is possible to build full computer vision applications on top of the VMX API, and you are highly encouraged to do so. The VMX GUI uses this VMX API from a Javascript(AngularJS) interface.  For documentation on how to use the GUI to perform training inside the browser, take a look at https://docs.vision.ai\n  \n  #### HTTP-based API\n  The VMX API is HTTP-based, so you can use the command line utility `curl`, `request` libraries in Node.js or python, jquery inside the browser, or just about another language which supports GET and POST requests.\n  \n  \n  \n  \n  #### JSON inputs and outputs\n  All inputs to VMX endpoints are JSON objects specified in the body of the request, and outputs are JSON objects with the information contained inside the `.data` field. If an error occurs, the API will return a non-200 error code and the returned JSON object will contain a `.error` field containing a human-readable error message.\n  \n  \nLet's start VMX and check the version.\n\n**On a Mac**\n```\ncd /Applications/VMX.app/Contents/MacOS/\n./run.sh\ncurl localhost:3000/check\n```\n\n**On Linux**\n```\ncd ~/vmx-docker-manager\n./vmx start 3000\ncurl localhost:3000/check\n```\n\n**If you are accessing a vision.ai hosted VMX node, check either port 80(http) or 443(https)**\n```\ncurl https://vmx.mycompany.com/check\n```\n\nFor a valid and licensed VMX node you should get something like:\n```\n{\n  \"uuid\": \"935169C6-C4E8-4393-875B-D80B5A998615\",\n  \"licensed\": true,\n  \"version\": [\n    \"VMXserver_Linux_v0.2.1\",\n    \"VMXmiddle_Linux_v0.4.1\",\n    \"vmxAppBuilder_v0.2.1\"\n  ]\n}\n```\n\nIf you're connecting to a VMX node with VMXserver v0.1, you'll need to update VMX. **These docs are for version v0.2.**\n  \n"},"definitions":{"Objectives":{"properties":{"obj_raw":{"type":"number","description":"The objective function value (without regularization terms added). The lower the better."},"obj":{"type":"number","description":"The objective function value (with regularization terms added). The lower the better."}}},"CreateSessionInput":{"properties":{"id":{"default":"","type":"string","description":"The desired session id, if not specified, will autogenerate one for you. The string must be alphanumeric, at least length 1, and the only valid non-alphanumeric character is the dash"}}},"ActivateInput":{"properties":{"email":{"type":"string","description":"your email address"}}},"LoadModelInput":{"required":["uuids"],"properties":{"compiled":{"example":false,"type":"boolean","description":"If enabled, will load the model in compiled mode. Compiled models are not editable, but they use less memory and are a bit faster for detection. When loading a collection of models, they will be in compiled mode. There is no way to load a collection of uncompiled models. Only one model can be uncompiled at a time."},"uuids":{"items":{"type":"string"},"type":"array","description":"A collection of UUIDs to load"}}},"Image":{"required":["image"],"properties":{"image":{"example":"http://people.csail.mit.edu/tomasz/img/tomasz_blue_crop.jpg","type":"string","description":"The base64 encoded image or URL pointing to image, works with base64 type prefix or not"},"objects":{"items":{"$ref":"#/definitions/Object"},"type":"array"}}},"ProcessImageInput":{"required":["images"],"properties":{"images":{"items":{"$ref":"#/definitions/Image"},"type":"array"},"params":{"$ref":"#/definitions/Params"},"name":{"default":"","type":"string","description":"The name of the detections we want. Useful if you have a session loaded with 100s of models, but you just want detections of a certain category. NOTE: currently not implemented"}}},"Config":{"properties":{"pretrained":{"type":"string","description":"The default pretrained file used for model creation when the `pretrained` field is empty inside `create_model`."},"log_images":{"default":false,"type":"boolean","description":"Whether to log full images or grep them out in the JSON-based session log. Both `create_model` and `process_image` operations contain dataURLs in the payload, so if you are going to be sharing logs, it is best practice to remove these dataURLs. The `edit_model` operation will contain dataURLs in the output.  If `log_images` is enabled, the dataURLs are replaced with the string \"IMAGE\""},"log_memory":{"default":false,"type":"boolean","description":"If enabled, will add `memory` field to each line of the JSON log. This is useful for debugging, but should not be used in production."},"allow_urls":{"default":true,"type":"boolean","description":"If enabled, will allow input images (for both `create_model` and `process_image` requests) to be URLs.  This is a very handy feature, but it is advised to turn this feature off for production."},"display_images":{"default":false,"type":"boolean","description":"If enabled, will render images and bounding boxes on your Desktop.  Only works on `Mac OS X`."},"read_only":{"default":false,"type":"boolean","description":"If enabled, will only allow read-only operations. This means `create_model`, `edit_model`, and `exit` won't work."}}},"SessionSummary":{"properties":{"model":{"$ref":"#/definitions/ModelSummary","description":"The model summary"},"id":{"type":"string","description":"The session id"}}},"CreateModelInput":{"required":["name","pretrained","images","params"],"properties":{"images":{"items":{"$ref":"#/definitions/Image"},"type":"array"},"pretrained":{"type":"string","description":"The pretrained file to use for model creation. Will default to the `pretrained` filed inside the `config.json` file next to the binary."},"params":{"$ref":"#/definitions/Params"},"name":{"type":"string"}}},"Settings":{"required":["max_positives","max_negatives"],"properties":{"learn_iterations":{"maximum":1000,"default":0,"minimum":0,"type":"integer","description":"The number of learning updates"},"pad_scale":{"maximum":2,"default":1,"minimum":0,"type":"number","description":"How much to pad around each exemplar, useful for showing extra context around an object. 1 is the defalut which shows a tight image crop around the exemplar. 0 will not even show images, and 2 will show 200% of the original exemplar."},"image_size":{"maximum":1000,"default":100,"minimum":0,"type":"integer","description":"The size of the resulting image crops (expressed as size of maximum dimension). A value of 0 will not even generate resulting images"},"max_negatives":{"default":20,"minimum":0,"type":"integer","description":"The maximum number of negatives to show"},"negatives_order":{"default":-1,"type":"integer","description":"The ordering on the negatives. 1 is ascending order, -1 is descending order."},"max_positives":{"default":20,"minimum":0,"type":"integer","description":"The maximum number of positives to show"},"positives_order":{"default":1,"type":"integer","description":"The ordering on the positives. 1 is ascending order, -1 is descending order."}}},"SaveModelInput":{"properties":{"name":{"example":"left_hand_up","default":"","type":"string","description":"If present and non-empty, will assign the new name to the model.  This will not change the UUID, just the `name` field that show up in listing models and assigning tags to detection boxes"},"new_uuid":{"example":false,"default":false,"type":"boolean","description":"If true, will assign a new UUID, effectively copying the model."}}},"ModelSummary":{"properties":{"image":{"example":"models/53255aee-f032-4df1-a61e-1502f1df33d4/image.jpg","type":"string","description":"image description (dataurl or image relative to vmx_dir)"},"history":{"items":{"type":"string"},"type":"array","description":"The name of the pretrained file used to generate the model. Will be an array of the individual models if model is a bundle."},"num_pos":{"type":"integer","description":"The number of positive examples in the model"},"num_neg":{"type":"integer","description":"The number of negative examples in the model"},"size":{"items":{"type":"integer"},"type":"array","description":"The size of the model"},"uuid":{"example":"17b86476-d430-4ecb-8185-aff17c18321c","type":"string","description":"The unique identifier for the model. Model bundles (collections of models) do not have hyphens in the UUID, and individual models have UUIDs in standard 36 character format"},"name":{"example":"tom's hand","type":"string","description":"A human readable model name"},"version":{"type":"string","description":"The version of VMX which generated this model"},"start_time":{"type":"string","description":"Model creation time"},"end_time":{"type":"string","description":"Last image/datapoint time"},"compiled":{"type":"boolean","description":"Whether the model is compiled or not"},"meta":{"type":"string","description":"Extra meta information about the model. Bundles will use comma separated names of individual models for the meta tag."}}},"Change":{"required":["id","class_label"],"properties":{"image":{"type":"string"},"class_label":{"type":"integer","description":"Should be -1 for negative, +1 for postive, and 0 for remove_me"},"time":{"type":"string","description":"Time associated with datapoint"},"score":{"type":"number"},"data":{"items":{"type":"number"},"type":"array"},"id":{"type":"integer","description":"The unique identifier for the exemplar"}}},"ConfigInput":{"properties":{"config":{"$ref":"#/definitions/Config"}}},"Params":{"properties":{"train_max_positives":{"default":1000,"minimum":1,"type":"integer","description":"The maximum number of positives inside the learned model.  VMX automatically adjust the number of positives (by dropping the least useful examples) when a larger number is reached when using learning mode."},"cell_size":{"default":4,"minimum":2,"type":"integer","description":"The spatial cell size (in pixels) used to analyze the input image.  This is the size of the regions for which statistical computations are performed."},"learn_iterations":{"default":10,"minimum":0,"type":"integer","description":"The number of learning iterations after each successful update while processing images in \"learn mode\"."},"max_image_size":{"default":320,"minimum":0,"type":"integer","description":"The maximum input image size (in number of pixels for either width or height).  You are free to send a larger image, but it will be resized to this size if the input is larger. Resizing maintains the aspect ratio, and makes sure that the maximum dimension is within this limit."},"initialize_max_cells":{"default":10,"minimum":1,"type":"integer","description":"The maximum template dimension (measured in cells) used during initialization. Model sizes are reported as #cells x #cells. This parameter makes sure that you don't get very large cell sizes for model creation. If you decide to create a model with initialize_max_cells set to a small value like 4, you might get models that are 2x4, 4x1, etc.  They will be really fast, but much coarser than your typical 8x10 models."},"crop_radius":{"default":80,"type":"integer","description":"The number of pixels around the object of interest to be used in crop mode.  This greatly improves the speed of the detector as fewer regions need to be analyzed. NOTE: this is only used inside the VMX GUI (aka vmxAppBuilder) but stored inside VMX as a convenience."},"max_windows":{"default":100,"minimum":0,"type":"integer","description":"The maximum number of raw detection windows to consider before applying non-maximum suppression.  The final number of detections will always be smaller than max_windows as non-maximum suppression will likely remove some.  The detector becomes really fast for max_windows=0, but it has better performance for large max_windows values."},"learn_threshold":{"default":0,"type":"number","description":"Object detections scoring above this threshold will be considered as positives while in `learn mode`. At most `learn_max_positives` will be treated as positives."},"train_max_negatives":{"default":2000,"minimum":1,"type":"integer","description":"The maximum number of positives inside the learned model.  VMX automatically adjust the number of positives (by dropping the least useful examples) when a larger number is reached when using learning mode."},"jpeg_quality":{"default":1,"type":"number","description":"The JPEG Quality factor controls the size (in MB) of the image but creates compression artifacts. Note: this is only used inside the VMX GUI (aka vmxAppBuilder) but stored inside the model as a convenience."},"display_threshold":{"default":0,"type":"number","description":"When using process_image, drop all detections below this threshold. Mac Only: Objects scoring above this threshold will be rendered on the screen when config.display_images is enabled."},"initialize_add_flip":{"default":false,"type":"boolean","description":"If enabled, model creation will add left-right flips of positives to generate 2X training data, then select the best of each flip."},"detect_add_flip":{"default":false,"type":"boolean","description":"If enabled, will perform detection on left-right flip of input image. Detection then takes twice as long, but only one image needs to be sent to the server."},"learn_max_positives":{"default":1,"minimum":0,"type":"integer","description":"The maximum number of positives which can be extracted from a single image during one step of `learn_mode`.  NOTE that to be considered a positive, then score must be above learn_threshold. You can make the detector treat everything as negatives by setting learn_max_positives to 0, and the learn_threshold to a really low value like -1.  You can make the detector treat all detections above 0 as positives by setting learn_max_positives to something large like 100 and the learn_threshold to 0.  NOTE: If you feed VMX an image with many true positives but learn_max_positives is set to 1, then only the highest scoring detection will be treated as a positive and the remaining detections as negatives."},"levels_per_octave":{"maximum":20,"default":10,"minimum":1,"type":"integer","description":"The levels per octave parameters describes how many different levels we use for object detection.  An octave is a halving of the original image, so 10 levels per octave means we will be looking at 10 different images sizes betwen the original and the halved image. Must be between 1 and 20. Lower will make detection faster, but be careful for scale-dependent blind spots."},"detect_max_overlap":{"maximum":1,"default":0.3,"minimum":0.0,"type":"number","description":"The non-maximum suppression threshold which will remove redundant (highly-overlapping windows).  This number ranges from [0,1] and 0 will not allow any returned detectections to overlap, while a 1.0 will keep all detection windows."},"learn_mode":{"default":false,"type":"boolean","description":"If enabled, go into learn mode."}}},"Object":{"required":["name","bb"],"properties":{"class_label":{"type":"integer","description":"optional class_label used to denote positives (+1), negatives (-1), or remove example (0)"},"score":{"type":"number","description":"optional score associated with example"},"data":{"maxLength":4,"items":{"type":"number"},"minLength":4,"type":"array","description":"Extra data stored with the example"},"bb":{"maxLength":4,"items":{"type":"number"},"minLength":4,"type":"array","description":"The object's bounding box (4 numbers)"},"name":{"example":"left_hand","type":"string","description":"The object's human readable name"},"id":{"type":"integer","description":"optional id used to index examples when using edit_model"}}},"EditModelInput":{"required":["changes","settings"],"properties":{"changes":{"items":{"$ref":"#/definitions/Change"},"type":"array"},"settings":{"$ref":"#/definitions/Settings"}}}},"paths":{"/forward":{"get":{"summary":"Forward from a remote IP camera to local","responses":{"200":{"description":"OK"}},"description":"Forward from a remote IP camera by using the ?q URL parameter","tags":["utility"]}},"/models/{modelUUID}/compiled.data":{"get":{"summary":"Get compiled model (binary format)","responses":{"404":{"description":"Model Not Found"},"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/ModelSummary"}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"modelUUID","type":"string","description":"UUID of the model"}],"description":"Get the compiled model in binary form","tags":["model_library"]}},"/sessions/{sessionId}/process":{"post":{"summary":"Process Image by applying current model.","responses":{"400":{"description":"Cannot process image"},"200":{"schema":{"properties":{"data":{"properties":{"objects":{"items":{"$ref":"#/definitions/Object"},"type":"array"},"model":{"$ref":"#/definitions/ModelSummary"}}}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"},{"required":true,"schema":{"$ref":"#/definitions/ProcessImageInput"},"in":"body","name":"body","description":"Process Image Payload"}],"description":"Process Image by applying current model. Even though the input must be an array of images, for detection and learning is only performed on the first image. Allows the model to grow in size by enabling `learning_mode`. Will not allow `learning_mode` when `config.read_only` is set to `true`.","tags":["detection"]}},"/random":{"get":{"summary":"Get a random image from the model library","responses":{"200":{"description":"OK"}},"tags":["utility"]}},"/sessions":{"post":{"summary":"Create a New Session","responses":{"409":{"schema":{"properties":{"error":{"type":"string","description":"A description of the error"}}},"description":"`id` already taken"},"400":{"schema":{"properties":{"error":{"type":"string","description":"A description of the error"}}},"description":"`id` contains illegal characters"},"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/SessionSummary"}}},"description":"OK"}},"parameters":[{"schema":{"$ref":"#/definitions/CreateSessionInput"},"in":"body","name":"body","description":"The new id"}],"description":"Create a new VMXworker session.  Each worker has its own unique id and is accessible at `/sessions/{sessionId}`. After session creation, you'll be able to load a collection of object detection models into the session (`/sessions/{sessionId}/load` route). You can get a randomly generated session id in the form of a uuid (**default behavior**), or you can provide the session id you want via the `id` field of the input json. *The user-specified `id` must contain only lowercase alphanumeric characters and a combination of hyphens and underscores.*\n#### Session Id Examples\n`b93f0157-a3ca-488b-99f5-2afd400f6c8b` is an example of a typical id autogenerated by VMX.\n`large-cat-faces`, `a`, and `body_parts-nov12` are valid session ids (as long as they aren't already used).\n\n`myDog`, `df!`, `car orientations`. and `Stop-sign` are all invalid session ids.\n\n##### Note on broken sessions\nIf your `/sessions/` listing doesn't show the taken SessionId, but you're getting a 409, then perhaps one of the VMXworkers was taken down abruptuly (this happens in development). Consider manually removing the contents of the `${VMX_DIR}/sessions/SessionId` folder.\n\n","tags":["session management"]},"get":{"summary":"List sessions","responses":{"200":{"schema":{"properties":{"data":{"items":{"$ref":"#/definitions/SessionSummary"},"type":"array"}}},"description":"OK"}},"description":"Lists the active VMXworker sessions. Returns the session ids and summaries of the models loaded in each session.\n\nGUI: <a href=\"/#/sessions\">/#/sessions</a> ","tags":["session management"]}},"/sessions/{sessionId}/log.txt":{"get":{"summary":"Get the last line of the log","responses":{"200":{"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"}],"description":"Get the last line of the log\n\n\nGUI: <a href=\"/#/sessions/sessionId/log.txt\">/#/sessions/sessionId/log.txt</a>\n","tags":["settings"]}},"/sessions/{sessionId}":{"post":{"summary":"Process Image by applying current model.","responses":{"400":{"description":"Cannot process image"},"200":{"schema":{"properties":{"data":{"properties":{"objects":{"items":{"$ref":"#/definitions/Object"},"type":"array"},"model":{"$ref":"#/definitions/ModelSummary"}}}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"},{"required":true,"schema":{"$ref":"#/definitions/ProcessImageInput"},"in":"body","name":"body","description":"Process Image Payload"}],"description":"Process Image by applying current model. Even though the input must be an array of images, for detection and learning is only performed on the first image. Allows the model to grow in size by enabling `learning_mode`. Will not allow `learning_mode` when `config.read_only` is set to `true`.","tags":["detection"]},"get":{"summary":"Get session info","responses":{"404":{"description":"Not Found"},"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/SessionSummary"}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"}],"tags":["session management"]},"delete":{"summary":"Delete current session from VMX","responses":{"404":{"description":"Session id not found"},"200":{"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"}],"tags":["session management"]}},"/sessions/{sessionId}/params":{"get":{"summary":"Get the detection params","responses":{"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/Params"}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"}],"description":"Get the detection params","tags":["settings"]}},"/activate/{LicenseKey}":{"post":{"summary":"Activate this copy of VMX","responses":{"200":{"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"LicenseKey","type":"string","description":"An unused VMX License Key"},{"required":true,"schema":{"$ref":"#/definitions/ActivateInput"},"in":"body","name":"body","description":"Licensing Payload"}],"description":"Activate this copy of VMX. A request is made to https://beta.vision.ai/ to obtain a valid license file for this machine. Requires an unused License Key.","tags":["activation"]}},"/models/{modelUUID}/image.jpg":{"get":{"summary":"Get model summary icon","responses":{"404":{"description":"Model Not Found"},"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/ModelSummary"}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"modelUUID","type":"string","description":"UUID of the model"}],"description":"Get the model summary icon","tags":["model_library"]}},"/sessions/{sessionId}/create":{"post":{"summary":"Create a new model","responses":{"400":{"description":"Unable to create model. Either `config.read_only` is set to `false` (see set_config) or there was a problem with your payload."},"200":{"schema":{"properties":{"data":{"properties":{"objectives":{"$ref":"#/definitions/Objectives"},"model":{"$ref":"#/definitions/ModelSummary"}}}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"},{"required":true,"schema":{"$ref":"#/definitions/CreateModelInput"},"in":"body","name":"body","description":"Model Creation payload"}],"description":"Create a new model given a dataset, a model name, a pretrained file, and detection/creation parameters.\n\n1.) Will look for the pretrained file inside the `data` directory specified in `config.json`,\n\n2.) If not present, will look for the pretrained file in the `/VMXdata/` directory (and copy it over to your `data` directory)\n\n3.) Will download the file from `https://files.vision.ai/vmx/pretrained/` (as long as `config.allow_urls` is set to true) into your `data` directory.\nVMXserver comes with two pretrained files. To get a listing of available pretrained files, run:\n`curl https://files.vision.ai/vmx/pretrained/MD5SUMS.json`\n","tags":["detection"]}},"/models":{"get":{"summary":"List models","responses":{"400":{"description":"Model Library Broken"},"200":{"schema":{"properties":{"data":{"items":{"$ref":"#/definitions/ModelSummary"},"type":"array"}}},"description":"OK"}},"description":"List the models inside `${VMX_DIR}` by returning a summary representation of each model\n\n\nGUI: <a href=\"/#/models\">/#/models</a> ","tags":["model_library"]}},"/models/{modelUUID}/model.data":{"get":{"summary":"Get full model (binary format)","responses":{"404":{"description":"Model Not Found"},"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/ModelSummary"}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"modelUUID","type":"string","description":"UUID of the model"}],"description":"Get the full uncompiled model in binary form","tags":["model_library"]}},"/models/{modelUUID}/model.json":{"get":{"summary":"Show model summary","responses":{"404":{"description":"Model Not Found"},"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/ModelSummary"}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"modelUUID","type":"string","description":"UUID of the model"}],"description":"Show the model summary. Same as `/models/{modelUUID}` ","tags":["model_library"]}},"/sessions/{sessionId}/load":{"post":{"summary":"Load models","responses":{"400":{"description":"Problem Loading Model(s)"},"200":{"schema":{"properties":{"data":{"properties":{"model":{"$ref":"#/definitions/ModelSummary"}}}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"},{"required":true,"schema":{"$ref":"#/definitions/LoadModelInput"},"in":"body","name":"body","description":"List of UUIDs and whether they should be compiled"}],"description":"Load one or moremodels from `${VMX_DIR}` into the worker. If a group of models is loaded, a bundle is created (a new model which contains the submodels) and saved. Loading will not work if `config.read_only` is `true`.","tags":["model_loading"]}},"/models/{modelUUID}/data_set/first.jpg":{"get":{"summary":"Get model's dataset's first image","responses":{"404":{"description":"Model Not Found"},"200":{"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"modelUUID","type":"string","description":"UUID of the model"}],"description":"Get the model's dataset as json","tags":["model_library"]}},"/models/{modelUUID}/data_set.json":{"get":{"summary":"Get model's dataset as json","responses":{"404":{"description":"Model Not Found"},"200":{"schema":{"properties":{"data":{"items":{"$ref":"#/definitions/Image"},"type":"array"}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"modelUUID","type":"string","description":"UUID of the model"}],"description":"Get the model's dataset as json","tags":["model_library"]}},"/models/{modelUUID}/data_set/random.jpg":{"get":{"summary":"Get model's dataset's random image","responses":{"404":{"description":"Model Not Found"},"200":{"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"modelUUID","type":"string","description":"UUID of the model"}],"description":"Get the model's dataset as json","tags":["model_library"]}},"/sessions/{sessionId}/config":{"post":{"summary":"Set the configuration object","responses":{"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/Config"}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"},{"schema":{"$ref":"#/definitions/ConfigInput"},"in":"body","name":"body","description":"Input Configuration Fields"}],"description":"Set the configuration object. Allows for only a subset of the available config fields to be present in the input payload.  In other words, you can set one config param at a time.","tags":["settings"]},"get":{"summary":"Get the configuration object","responses":{"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/Config"}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"}],"description":"Get the configuration object","tags":["settings"]}},"/models/{modelUUID}":{"get":{"summary":"Show model summary","responses":{"404":{"description":"Model Not Found"},"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/ModelSummary"}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"modelUUID","type":"string","description":"UUID of the model"}],"description":"Show the model summary","tags":["model_library"]}},"/sessions/{sessionId}/edit":{"post":{"summary":"Edit model","responses":{"400":{"description":"Cannot edit model"},"200":{"schema":{"properties":{"data":{"properties":{"images":{"items":{"$ref":"#/definitions/Image"},"type":"array"},"objectives":{"$ref":"#/definitions/Objectives"}}}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"},{"required":true,"schema":{"$ref":"#/definitions/EditModelInput"},"in":"body","name":"body","description":"Edit Model Payload"}],"description":"Edit/show the positive examples inside the model. Can be used to show image crops of the positives/negatives, swap examples, or remove examples.\n\n\nGUI: <a href=\"/#/sessions/sessionId/edit\">/#/sessions/sessionId/edit</a>\n","tags":["detection"]}},"/sessions/{sessionId}/save":{"post":{"summary":"Save currently loaded model","responses":{"400":{"description":"Problem saving model"},"200":{"schema":{"properties":{"data":{"properties":{"model":{"$ref":"#/definitions/ModelSummary"},"compiled_MB":{"type":"number","description":"The size of the compiled model in Megabytes"},"full_MB":{"type":"number","description":"The size of the full model in Megabytes"}}}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"},{"required":true,"schema":{"$ref":"#/definitions/SaveModelInput"},"in":"body","name":"body","description":"Information about the saved model"}],"description":"Save the currently loaded model into the `${VMX_DIR}` directory. Allows for renaming the model as well as generating a new UUID for the saved model. If the currently loaded model is a bundle, then a new UUID cannot be generated since bundle UUIDs are determined from the component UUIDs. Will not allow save operation when `config.read_only` is set to `true`.","tags":["model_loading"]}},"/models/{modelUUID}/reset_cache":{"post":{"summary":"Reset model cache","responses":{"404":{"description":"Model Not Found"},"200":{"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"modelUUID","type":"string","description":"UUID of the model"}],"description":"Reset model cache","tags":["model_library"]}},"/check":{"get":{"summary":"Check VMX version and whether it is activated","responses":{"200":{"schema":{"properties":{"uuid":{"type":"string","description":"The identifier for this VMX install"},"licensed":{"type":"boolean","description":"Whether this copy is licensed or not"},"version":{"items":{"type":"string"},"type":"array","description":"The three versions of the VMX components used in this install"}}},"description":"OK"}},"description":"Check VMX version","tags":["activation"]}},"/models/{modelUUID}/data_set/image.jpg":{"get":{"summary":"Get model's dataset's next image","responses":{"404":{"description":"Model Not Found"},"200":{"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"modelUUID","type":"string","description":"UUID of the model"}],"description":"Get the model's dataset as json","tags":["model_library"]}}}}
